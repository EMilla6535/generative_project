{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-04-30T02:45:18.706494Z","iopub.status.busy":"2024-04-30T02:45:18.706149Z","iopub.status.idle":"2024-04-30T02:45:31.645071Z","shell.execute_reply":"2024-04-30T02:45:31.644066Z","shell.execute_reply.started":"2024-04-30T02:45:18.706464Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import keras\n","\n","@keras.saving.register_keras_serializable(package=\"TrainModel\")\n","class SelfAttention(tf.keras.layers.Layer):\n","    def __init__(self, channels, size):\n","        super(SelfAttention, self).__init__()\n","        self.channels = channels\n","        self.size = size\n","        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=channels)\n","        self.ln = tf.keras.layers.LayerNormalization()\n","    def call(self, x):\n","        x = tf.reshape(x, [-1, self.size * self.size, self.channels])\n","        x_ln = self.ln(x)\n","        attention_value = self.mha(query=x_ln, key=x_ln, value=x_ln)\n","        attention_value = attention_value + x\n","        attention_value = tf.reshape(attention_value, [-1, self.size, self.size, self.channels])\n","        return attention_value\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"channels\": self.channels,\n","            \"size\": self.size\n","        })\n","        return config\n","\n","@keras.saving.register_keras_serializable(package=\"TrainModel\")\n","class Upsample(tf.keras.layers.Layer):\n","    def __init__(self, outc):\n","        super(Upsample, self).__init__()\n","        self.outc = outc\n","        self.up = tf.keras.layers.UpSampling2D(size=2, interpolation='nearest')\n","        self.conv = tf.keras.layers.Conv2D(outc, kernel_size=3, padding='same', use_bias=False)\n","    def call(self, x):\n","        x = self.up(x)\n","        x = self.conv(x)\n","        return x\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"outc\": self.outc\n","        })\n","        return config\n","\n","@keras.saving.register_keras_serializable(package=\"TrainModel\")\n","class Downsample(tf.keras.layers.Layer):\n","    def __init__(self, outc):\n","        super(Downsample, self).__init__()\n","        self.outc = outc\n","        # Alternative: Reduce using Conv2D\n","        self.down = tf.keras.layers.MaxPooling2D(2)\n","        self.conv = tf.keras.layers.Conv2D(outc, kernel_size=3, padding='same', use_bias=False)\n","    def call(self, x):\n","        x = self.down(x)\n","        x = self.conv(x)\n","        return x\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"outc\": self.outc\n","        })\n","        return config\n","\n","@keras.saving.register_keras_serializable(package=\"TrainModel\")\n","class Block(tf.keras.layers.Layer):\n","    def __init__(self, outc):\n","        super(Block, self).__init__()\n","        self.outc = outc\n","        self.block = tf.keras.Sequential([\n","            tf.keras.layers.Conv2D(outc, kernel_size=3, padding='same', use_bias=False),\n","            tf.keras.layers.BatchNormalization(axis=-1), # or GroupNormalization\n","            tf.keras.layers.Activation('relu') # or Swish\n","        ])\n","    def call(self, x):\n","        x = self.block(x)\n","        return x\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"outc\": self.outc\n","        })\n","        return config\n","\n","@keras.saving.register_keras_serializable(package=\"TrainModel\")\n","class ResnetBlock(tf.keras.layers.Layer):\n","    def __init__(self, outc):\n","        super(ResnetBlock, self).__init__()\n","        self.outc = outc\n","        self.block1 = Block(outc)\n","        self.block2 = Block(outc)\n","        self.emb = tf.keras.Sequential([\n","            tf.keras.layers.Activation('silu'),\n","            tf.keras.layers.Dense(outc)\n","        ])\n","    def call(self, x, t):\n","        \"\"\"\n","        Alternativa:\n","        x_b = x + emb\n","        x_b = self.block1(x_b)\n","        x_b = x_b + emb\n","        x_b = self.block2(x)\n","        return x_b + self.res_conv(x)\n","        \"\"\"\n","        x_b = self.block1(x)\n","        emb = tf.tile(self.emb(t)[:, None, None, :], [1, x.shape[-3], x.shape[-2], 1])\n","        x_b = x_b + emb\n","        x_b = self.block2(x_b)\n","        return x_b\n","    def build(self, input_shape):\n","        super().build(input_shape)\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"outc\": self.outc\n","        })\n","        return config\n","    \n","@keras.saving.register_keras_serializable(package=\"TrainModel\")\n","class PositionalEncoding(tf.keras.layers.Layer):\n","    def __init__(self, dim):\n","        super().__init__()\n","        self.dim = dim\n","    \n","    def call(self, noise_level):\n","        count = self.dim // 2\n","        step = tf.range(count, dtype='float32') / count\n","        arg1 = tf.cast(-tf.math.log(1e4), dtype='float32')\n","        arg2 = tf.cast(tf.expand_dims(step, axis=0), dtype='float32')\n","        encoding = tf.cast(tf.expand_dims(noise_level, axis=1), dtype='float32') * tf.cast(tf.math.exp(arg1 * arg2), dtype='float32')\n","        encoding = tf.concat([tf.math.sin(encoding), tf.math.cos(encoding)], axis=-1)\n","        return tf.squeeze(encoding, axis=1)\n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"dim\": self.dim\n","        })\n","        return config\n","\n","@keras.saving.register_keras_serializable(package=\"TrainModel\")\n","class DiffusionModel(tf.keras.Model):\n","    def __init__(self, \n","                 in_ch=3, \n","                 out_ch=3, \n","                 inner_channel=128, \n","                 ch_mult=(1, 2, 4, 4, 8, 8), \n","                 bot_blocks=2, \n","                 image_size=256, \n","                 noise_steps=1000, \n","                 pred_steps=1000, \n","                 beta_start=1e-4, \n","                 beta_end=0.02, \n","                 *args, \n","                 **kwargs):\n","        super().__init__(*args, **kwargs)\n","        self.in_ch = in_ch\n","        self.out_ch = out_ch\n","        self.inner_channel = inner_channel\n","        self.ch_mult = ch_mult\n","        self.bot_blocks = bot_blocks\n","        \n","        num_mults = len(ch_mult)\n","        self.noise_encoder = tf.keras.Sequential([PositionalEncoding(inner_channel)])\n","        self.in_conv = tf.keras.layers.Conv2D(inner_channel, kernel_size=3, padding='same', use_bias=False)\n","\n","        self.down_layers = []\n","        self.down_resnet = []\n","\n","        for i in range(1, num_mults, 1):\n","            self.down_layers.append(Downsample(inner_channel * ch_mult[i]))\n","            self.down_resnet.append(ResnetBlock(inner_channel * ch_mult[i]))\n","        \n","        self.self_att1 = SelfAttention(inner_channel * ch_mult[-1], image_size // (2 ** (num_mults - 1)))\n","        self.bot_layers = []\n","\n","        for i in range(bot_blocks):\n","            self.bot_layers.append(ResnetBlock(inner_channel * ch_mult[-1]))\n","        \n","        self.up_layers = []\n","        self.up_resnet = []\n","\n","        for i in range(num_mults - 2, -1, -1):\n","            self.up_layers.append(Upsample(inner_channel * ch_mult[i]))\n","            self.up_resnet.append(ResnetBlock(inner_channel * ch_mult[i]))\n","        \n","        self.out_conv = tf.keras.layers.Conv2D(3, kernel_size=3, padding='same')\n","\n","        # Params\n","        self.noise_steps = 1000\n","        self.img_size = image_size\n","        self.pred_nsteps = 200\n","        self.beta_start = 1e-4\n","        self.beta_end = 0.02\n","\n","        self.beta = tf.linspace(self.beta_start, self.beta_end, self.noise_steps)\n","        self.alpha = 1.0 - self.beta\n","        self.gamma = tf.math.cumprod(self.alpha, axis=0)\n","\n","        self.noise_rng = tf.random.Generator.from_non_deterministic_state()\n","    \n","    def call(self, x, t):\n","        t = self.noise_encoder(t)\n","        residuals = [self.in_conv(x)]\n","        for down, resnet in zip(self.down_layers, self.down_resnet):\n","            residuals.append(resnet(down(residuals[-1]), t))\n","        \n","        x = residuals.pop()\n","        x = self.self_att1(x)\n","        for bot in self.bot_layers:\n","            x = bot(x, t)\n","        \n","        for up, resnet in zip(self.up_layers, self.up_resnet):\n","            x = resnet(tf.concat([up(x), residuals.pop()], axis=-1), t)\n","        \n","        x = self.out_conv(x)\n","        return x\n","    \n","    def noise_inputs(self, x, s, u_scale, epsilon):\n","        l_a, l_b = tf.gather(self.gamma, s - 1), tf.gather(self.gamma, s)\n","        noise_scale = l_a + u_scale * (l_b - l_a)\n","        sqrt_noise_scale = tf.math.sqrt(noise_scale)[:, :, None, None]\n","        sqrt_one_minus_noise_scale = tf.math.sqrt(1.0 - noise_scale)[:, :, None, None]\n","        return sqrt_noise_scale * x + sqrt_one_minus_noise_scale * epsilon\n","    \n","    def train_step(self, data):\n","        y, rnd = data\n","        s, u_scale, noise = rnd\n","        y_t = self.noise_inputs(y, s, u_scale, noise)\n","        with tf.GradientTape() as tape:\n","            predicted_noise = self(y_t, s, training=True)\n","            loss_value = self.compute_loss(y=noise, y_pred=predicted_noise)\n","        \n","        trainable_vars = self.trainable_variables\n","        gradients = tape.gradient(loss_value, trainable_vars)\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","        for metric in self.metrics:\n","            if metric.name == \"loss\":\n","                metric.update_state(loss_value)\n","            else:\n","                metric.update_state(noise, predicted_noise)\n","        return {m.name: m.result() for m in self.metrics}\n","    \n","    @tf.function\n","    def predict_step(self, data):\n","        y_t = data\n","        for i in tf.range(self.pred_nsteps - 1, 0, -1, dtype='int32'):\n","            t = tf.cast(tf.ones(y_t.shape[0]), 'int32') * i\n","            predicted_noise = self(y_t, t, training=False)\n","            alpha = tf.gather(self.alpha, t)[:, None, None, None]\n","            gamma = tf.gather(self.gamma, t)[:, None, None, None]\n","            if i > 1:\n","                noise = self.noise_rng.normal(shape=y_t.shape, mean=0.0, stddev=1.0, dtype='float32')\n","            else:\n","                noise = tf.zeros_like(y_t)\n","            y_t = (1 / tf.math.sqrt(alpha)) * (y_t - ((1.0 - alpha) / (tf.math.sqrt(1.0 - gamma))) * predicted_noise) + (tf.math.sqrt(1.0 - alpha) * noise)\n","        return y_t\n","    \n","    def build(self, input_shape):\n","        super().build(input_shape)\n","        \n","    def get_config(self):\n","        config = super().get_config()\n","        config.update({\n","            \"in_ch\": self.in_ch,\n","            \"out_ch\": self.out_ch,\n","            \"inner_channel\": self.inner_channel,\n","            \"ch_mult\": self.ch_mult,\n","            \"bot_blocks\": self.bot_blocks,\n","            \"image_size\": self.img_size,\n","            \"noise_steps\": self.noise_steps,\n","            \"pred_steps\": self.pred_nsteps,\n","            \"beta_start\": self.beta_start,\n","            \"beta_end\": self.beta_end\n","        })\n","        return config\n","    \n","    @classmethod\n","    def from_config(cls, config):\n","        config[\"in_ch\"] = keras.saving.deserialize_keras_object(config[\"in_ch\"])\n","        config[\"out_ch\"] = keras.saving.deserialize_keras_object(config[\"out_ch\"])\n","        config[\"inner_channel\"] = keras.saving.deserialize_keras_object(config[\"inner_channel\"])\n","        config[\"ch_mult\"] = keras.saving.deserialize_keras_object(config[\"ch_mult\"])\n","        config[\"bot_blocks\"] = keras.saving.deserialize_keras_object(config[\"bot_blocks\"])\n","        config[\"image_size\"] = keras.saving.deserialize_keras_object(config[\"image_size\"])\n","        \n","        config[\"noise_steps\"] = keras.saving.deserialize_keras_object(config[\"noise_steps\"])\n","        config[\"pred_steps\"] = keras.saving.deserialize_keras_object(config[\"pred_steps\"])\n","        config[\"beta_start\"] = keras.saving.deserialize_keras_object(config[\"beta_start\"])\n","        config[\"beta_end\"] = keras.saving.deserialize_keras_object(config[\"beta_end\"])\n","\n","        return cls(**config)\n","    \n","    def get_build_config(self):\n","        build_config = super().get_build_config()\n","        return build_config\n","    \n","    def build_from_config(self, config):\n","        self.build(config[\"input_shape\"])\n","\n","rng = tf.random.Generator.from_non_deterministic_state()\n","normal = rng.normal(shape=[9, 256, 256, 3], mean=0.0, stddev=1.0, dtype='float32')\n","t_sample = rng.uniform(shape=[9, 1], minval=1, maxval=1000, dtype='int32')\n","\n","#model = DiffusionModel(inner_channel=64, ch_mult=(1, 2, 4, 8), bot_blocks=3, image_size=64)#UNet()\n","#model(normal, t_sample)\n","#model.summary()"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T02:45:31.647158Z","iopub.status.busy":"2024-04-30T02:45:31.646642Z","iopub.status.idle":"2024-04-30T02:45:31.756800Z","shell.execute_reply":"2024-04-30T02:45:31.755776Z","shell.execute_reply.started":"2024-04-30T02:45:31.647129Z"},"trusted":true},"outputs":[],"source":["# Load pre processed dataset\n","import os\n","from shutil import make_archive\n","from zipfile import ZipFile\n","\n","\"\"\"\n","Dataset:\n","x = image_size -> 256\n","s = uniform(shape=[batch], minval=1, maxval=noise_steps, dtype='int32')\n","u_scale = uniform(shape[batch], minval=0.0, maxval=1.0, dtype='float32')\n","noise = normal(shape[batch, img_size, img_size, channels], mean=0.0, stddev=1.0)\n","\"\"\"\n","def random_generator(img_shape, s_shape, noise_steps):\n","    rng = tf.random.Generator.from_non_deterministic_state()\n","    s_uniform_gen = rng.uniform(shape=s_shape, minval=1, maxval=noise_steps, dtype='int32')\n","    u_uniform_gen = rng.uniform(shape=s_shape, minval=0.0, maxval=1.0, dtype='float32')\n","    normal_gen = rng.normal(shape=img_shape, mean=0.0, stddev=1.0, dtype='float32')\n","    for s, u, noise in zip(s_uniform_gen, u_uniform_gen, normal_gen):\n","        yield s, u, noise\n","\n","def get_random_ds(image_size, n_items, noise_steps):\n","    random_ds = tf.data.Dataset.from_generator(random_generator,\n","                                               args=([n_items, image_size, image_size, 3], [n_items, 1], noise_steps),\n","                                               output_signature=(\n","                                                   tf.TensorSpec(shape=(1), dtype='int32'),\n","                                                   tf.TensorSpec(shape=(1), dtype='float32'),\n","                                                   tf.TensorSpec(shape=(image_size, image_size, 3), dtype='float32')))\n","    return random_ds.repeat(count=None)\n","\n","batch_size = 9\n","#img_dataset = tf.data.Dataset.load('/kaggle/input/dataset-maker/256_0_1000_dataset/dataset')\n","img_dataset = tf.data.Dataset.load('/kaggle/input/dataset-maker/256_1000_2000_dataset/dataset')\n","#img_dataset = tf.data.Dataset.load('/kaggle/input/dataset-maker/256_2000_3000_dataset/dataset')\n","#img_dataset = tf.data.Dataset.load('/kaggle/input/dataset-maker/256_3000_4319_dataset/dataset')\n","\n","n_train = img_dataset.cardinality().numpy()\n","rnd_dataset = get_random_ds(256, n_train, 1000)\n","train_dataset = tf.data.Dataset.zip(img_dataset, rnd_dataset).shuffle(n_train).batch(batch_size).prefetch(batch_size)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-04-30T02:45:31.758968Z","iopub.status.busy":"2024-04-30T02:45:31.758522Z","iopub.status.idle":"2024-04-30T02:56:19.491410Z","shell.execute_reply":"2024-04-30T02:56:19.490258Z","shell.execute_reply.started":"2024-04-30T02:45:31.758934Z"},"trusted":true},"outputs":[],"source":["# Train model\n","import os\n","import glob\n","from shutil import make_archive\n","from zipfile import ZipFile\n","\n","# Check if result path exists\n","if not os.path.exists('/kaggle/working/result_images'):\n","    os.makedirs('/kaggle/working/result_images')\n","\n","# Load sample images to test model\n","class SampleCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        if (epoch + 1) % 10 == 0:\n","            test_img = []\n","            filepath = '/kaggle/input/test64/test'\n","            rescaling_layer = tf.keras.layers.Rescaling(scale=1./255)\n","            upsample_layer = tf.keras.layers.UpSampling2D(size=4, data_format='channels_last', interpolation='bicubic')\n","            for filename in glob.glob(filepath + '/*.jpg'):\n","                raw = tf.io.read_file(filename)\n","                image = tf.io.decode_jpeg(raw, channels=3)\n","                image = rescaling_layer(image)\n","                image = upsample_layer(tf.expand_dims(image, axis=0))\n","                test_img.append(image.numpy().tolist())\n","            test_img = tf.constant(test_img)\n","            test_img = tf.squeeze(test_img, axis=1)\n","            # Rescaled image, noise\n","            rng = tf.random.Generator.from_non_deterministic_state()\n","            \n","            s = tf.ones(test_img.shape[0], dtype='int32') * 2\n","            u = tf.ones(test_img.shape[0], dtype='float32') * 0.5\n","            s = tf.expand_dims(s, axis=-1)\n","            u = tf.expand_dims(u, axis=-1)\n","\n","            noise = rng.normal(shape=test_img.shape, mean=0.0, stddev=1.0, dtype='float32')\n","            in_data = self.model.noise_inputs(test_img, s, u, noise)\n","            result = self.model.predict(in_data, batch_size=test_img.shape[0])\n","            for i in range(result.shape[0]):\n","                tf.keras.utils.save_img(f'result_images/{epoch}_result_{i}.jpg', result[i], data_format='channels_last', scale=True)\n","\n","epochs = 100\n","\n","mc = tf.keras.callbacks.ModelCheckpoint('super_res.weights.h5', monitor='loss', save_best_only=True, mode='min', save_weights_only=True)\n","sc = SampleCallback()\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4)\n","mse_loss = tf.keras.losses.MeanSquaredError()\n","\n","first_train = False\n","\n","if first_train:\n","    model = DiffusionModel(bot_blocks=3, pred_steps=50)\n","    model.compile(optimizer=optimizer, loss=mse_loss, metrics=['mse'])\n","    model.fit(train_dataset, epochs=epochs, callbacks=[mc, sc])\n","else:\n","    loaded_model = DiffusionModel(bot_blocks=3, pred_steps=70)\n","    loaded_model(normal, t_sample)\n","    loaded_model.load_weights(\"/kaggle/input/res-generative/super_res.weights.h5\")\n","    loaded_model.compile(optimizer=optimizer, loss=mse_loss, metrics=['mse'])\n","    # Re-train\n","    loaded_model.fit(train_dataset, epochs=epochs, callbacks=[mc, sc])\n","\n","filename = \"sampled_results\"\n","directory = \"result_images\"\n","make_archive(filename, \"zip\", directory)\n","print(\"Finished!\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4452587,"sourceId":7769714,"sourceType":"datasetVersion"},{"datasetId":4706860,"sourceId":7994686,"sourceType":"datasetVersion"},{"datasetId":4711720,"sourceId":8001153,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
