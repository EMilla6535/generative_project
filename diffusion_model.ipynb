{"cells":[{"cell_type":"code","execution_count":5,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-03-30T03:01:08.246493Z","iopub.status.busy":"2024-03-30T03:01:08.246130Z","iopub.status.idle":"2024-03-30T03:01:08.321273Z","shell.execute_reply":"2024-03-30T03:01:08.320411Z","shell.execute_reply.started":"2024-03-30T03:01:08.246462Z"},"trusted":true},"outputs":[],"source":["import tensorflow as tf\n","import keras\n","\n","#tf.config.run_functions_eagerly(True)\n","@keras.saving.register_keras_serializable(package=\"TrainModel\")\n","class SelfAttention(tf.keras.layers.Layer):\n","    def __init__(self, channels, size, prefix):\n","        super(SelfAttention, self).__init__()\n","        self.channels = channels\n","        self.size = size\n","        self.mha = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=channels, name=f'{prefix}_SA_mha')\n","        self.ln = tf.keras.layers.LayerNormalization()\n","        self.ff_self = tf.keras.Sequential([\n","            tf.keras.layers.LayerNormalization(name=f'{prefix}_SA_layer_norm'),\n","            tf.keras.layers.Dense(channels, name=f'{prefix}_SA_dense_1'),\n","            tf.keras.layers.Activation('gelu', name=f'{prefix}_SA_gelu_act'),\n","            tf.keras.layers.Dense(channels, name=f'{prefix}_SA_dense_2')\n","        ], name=f'{prefix}_SA_sequential')\n","    def call(self, x):\n","        x = tf.reshape(x, [-1, self.size * self.size, self.channels])\n","        #print(x.shape)\n","        x_ln = self.ln(x)\n","        attention_value = self.mha(query=x_ln, key=x_ln, value=x_ln)\n","        attention_value = attention_value + x\n","        attention_value = self.ff_self(attention_value) + attention_value\n","        #print(attention_value.shape)\n","        attention_value = tf.reshape(x, [-1, self.size, self.size, self.channels])\n","        #print(attention_value.shape)\n","        return attention_value\n","\n","@keras.saving.register_keras_serializable(package=\"TrainModel\")\n","class DoubleConv(tf.keras.layers.Layer):\n","    def __init__(self, in_channels, out_channels, mid_channels=None, prefix='', residual=False):\n","        super().__init__()\n","        self.residual = residual\n","        if not mid_channels:\n","            mid_channels = out_channels\n","        # Conv2D & GroupNormalization podrian causar problemas\n","        self.double_conv = tf.keras.Sequential([\n","            tf.keras.layers.Conv2D(mid_channels, kernel_size=3, padding='same', use_bias=False, name=f'{prefix}_DC_conv_1'), # False\n","            tf.keras.layers.GroupNormalization(groups=1, axis=-1, name=f'{prefix}_DC_group_norm_1'),#, epsilon=1e-5),\n","            tf.keras.layers.Activation('gelu', name=f'{prefix}_DC_gelu_act'),\n","            tf.keras.layers.Conv2D(out_channels, kernel_size=3, padding='same', use_bias=False, name=f'{prefix}_DC_conv_2'), # False\n","            tf.keras.layers.GroupNormalization(groups=1, axis=-1, name=f'{prefix}_DC_group_norm_2')#, epsilon=1e-5)\n","        ], name=f'{prefix}_DC_sequential')\n","    def call(self, x):\n","        if self.residual:\n","            return tf.nn.gelu(x + self.double_conv(x))\n","        else:\n","            return self.double_conv(x)\n","\n","@keras.saving.register_keras_serializable(package=\"TrainModel\")\n","class Down(tf.keras.layers.Layer):\n","    def __init__(self, in_channels, out_channels, prefix, emb_dim=256):\n","        super().__init__()\n","        self.maxpool_conv = tf.keras.Sequential([\n","            tf.keras.layers.MaxPooling2D(2, name=f'{prefix}_DN_max_pool'),\n","            DoubleConv(in_channels, in_channels, residual=True, prefix=f'{prefix}_Down_1_'),\n","            DoubleConv(in_channels, out_channels, prefix=f'{prefix}_Down_2_'),\n","        ], name=f'{prefix}_DN_sequential_1')\n","        self.emb_layer = tf.keras.Sequential([\n","            tf.keras.layers.Activation('silu', name=f'{prefix}_DN_silu_act'),\n","            tf.keras.layers.Dense(out_channels, name=f'{prefix}_DN_dense')\n","        ], name=f'{prefix}_DN_sequential_2')\n","    def call(self, x, t):\n","        x = self.maxpool_conv(x)\n","        emb = tf.tile(self.emb_layer(t)[:, None, None, :], [1, x.shape[-3], x.shape[-2], 1])\n","        return x + emb\n","        #return x\n","\n","@keras.saving.register_keras_serializable(package=\"TrainModel\")\n","class Up(tf.keras.layers.Layer):\n","    def __init__(self, in_channels, out_channels, prefix, emb_dim=256):\n","        super().__init__()\n","        # Upsampling podria no funcionar por align_corners\n","        self.up = tf.keras.layers.UpSampling2D(size=2, interpolation=\"bilinear\", name=f'{prefix}_UP_upsample')\n","        #self.up = tf.keras.layers.Conv2DTranspose(in_channels // 2, kernel_size=3, strides=2, padding='same', data_format='channels_last')\n","        self.conv = tf.keras.Sequential([\n","            DoubleConv(in_channels, in_channels, residual=True, prefix=f'{prefix}_Up_1_'),\n","            DoubleConv(in_channels, out_channels, in_channels // 2, prefix=f'{prefix}_Up_2_')\n","        ], name=f'{prefix}_UP_sequential_1')\n","        self.emb_layer = tf.keras.Sequential([\n","            tf.keras.layers.Activation('silu', name=f'{prefix}_UP_silu_act'),\n","            tf.keras.layers.Dense(out_channels, name=f'{prefix}_UP_dense')\n","        ], name=f'{prefix}_UP_sequential_2')\n","    def call(self, x, skip_x, t):\n","        x = self.up(x)\n","        x = tf.concat([skip_x, x], axis=-1)\n","        x = self.conv(x)\n","        emb = tf.tile(self.emb_layer(t)[:, None, None, :], [1, x.shape[-3], x.shape[-2], 1])\n","        return x + emb\n","        #return x\n","\n","@keras.saving.register_keras_serializable(package=\"TrainModel\")\n","class DiffusionTraining(tf.keras.Model):\n","    def set_diffusion_args(self, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=64):\n","        self.noise_layer = tf.keras.layers.GaussianNoise(stddev=1.0, name='DT_gauss_noise')\n","        self.noise_steps = noise_steps\n","        self.beta_start = beta_start\n","        self.beta_end = beta_end\n","        self.img_size = img_size\n","        \n","        self.beta = tf.linspace(self.beta_start, self.beta_end, self.noise_steps)\n","        self.alpha = 1.0 - self.beta\n","        self.alpha_hat = tf.math.cumprod(self.alpha, axis=0)\n","        \n","    def noise_images(self, x, t, training=True):\n","        sqrt_alpha_hat = tf.math.sqrt(tf.gather(self.alpha_hat, t))[:, None, None, None]\n","        sqrt_one_minus_alpha_hat = tf.math.sqrt(1 - tf.gather(self.alpha_hat, t))[:, None, None, None]\n","        epsilon = self.noise_layer(x, training=training)\n","        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * epsilon, epsilon\n","    \n","    @tf.function\n","    def train_step(self, data):\n","        x, t = data\n","        #noise = self.noise_layer(x, training=True)\n","        t = tf.transpose(t)[0]\n","        x, noise = self.noise_images(x, t)\n","        with tf.GradientTape() as tape:\n","            predicted_noise = self((x, t), training=True)\n","            loss_value = self.compute_loss(y=noise, y_pred=predicted_noise)\n","        # Compute gradients\n","        trainable_vars = self.trainable_variables\n","        #print(f\"Trainable vars: {len([var.path for var in trainable_vars])}\")\n","        #for var in trainable_vars:\n","        #    print(var.path)\n","        #print(f\"Watched vars: {len([var.name for var in tape.watched_variables()])}\")\n","        #for var in tape.watched_variables():\n","        #    print(var.name)\n","        gradients = tape.gradient(loss_value, trainable_vars)\n","        # Update weights\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","        # Update metrics (includes the metric that tracks the loss)\n","        for metric in self.metrics:\n","            if metric.name == \"loss\":\n","                metric.update_state(loss_value)\n","            else:\n","                metric.update_state(x, predicted_noise)\n","        # Return a dict mapping metric names to current value\n","        return {m.name: m.result() for m in self.metrics}\n","    @tf.function\n","    def predict_step(self, data):\n","        for i in tf.range(self.noise_steps - 1, 0, -1, dtype='int32'):\n","            t = tf.cast(tf.ones([data.shape[0]]), dtype='int32') * i\n","            predicted_noise = self((data, t), training=False)\n","            alpha = tf.gather(self.alpha, t)[:, None, None, None]\n","            alpha_hat = tf.gather(self.alpha_hat, t)[:, None, None, None]\n","            beta = tf.gather(self.beta, t)[:, None, None, None]\n","            if i > 1:\n","                noise = self.noise_layer(tf.ones([data.shape[0], self.img_size, self.img_size, 3]), training=True)\n","            else:\n","                noise = tf.zeros_like(data)\n","            data = 1 / tf.math.sqrt(alpha) * (data - ((1 - alpha) / (tf.math.sqrt(1 - alpha_hat))) * predicted_noise) + tf.math.sqrt(beta) * noise\n","        return data #? o save_img\n","    \n","    def sample_step(self, x, n=3):\n","        # Load images & compare with prediction\n","        rng = tf.random.Generator.from_non_deterministic_state()\n","        #noise = rng.normal(shape=[n, self.img_size, self.img_size, 3], mean=0.0, stddev=1.0, dtype='float32')\n","        ts = rng.uniform(shape=[n], minval=1, maxval=self.noise_steps, dtype='int32')\n","        \n","        x_t, noise = self.noise_images(x, ts)\n","        prediction = self((x_t, ts), training=False)\n","        return prediction, noise, x_t\n","\n","def pos_encoding(t, channels):\n","    inv_freq = 1.0 / (\n","        10000\n","        ** (tf.range(0, channels, 2, dtype='float32') / channels)\n","    )\n","    pos_enc_a = tf.math.sin(tf.tile(t, [1, channels // 2]) * inv_freq)\n","    pos_enc_b = tf.math.cos(tf.tile(t, [1, channels // 2]) * inv_freq)\n","    pos_enc = tf.concat([pos_enc_a, pos_enc_b], axis=-1)\n","    return pos_enc\n","\n","@keras.saving.register_keras_serializable(package=\"TrainModel\")\n","class PosEncLayer(tf.keras.layers.Layer):\n","    #def __init__(self):\n","    #    super(PosEncLayer, self).__init__()\n","    \n","    def call(self, inputs, time_dim=256):\n","        #inputs = tf.squeeze(inputs, axis=0)\n","        t = tf.cast(tf.expand_dims(inputs, -1), dtype='float32')\n","        t = pos_encoding(t, time_dim)\n","        return t\n","    \n","    def pos_encoding(self, t, channels):\n","        inv_freq = 1.0 / (\n","            10000\n","            ** (tf.range(0, channels, 2, dtype='float32') / channels)\n","        )\n","        pos_enc_a = tf.math.sin(tf.tile(t, [1, channels // 2]) * inv_freq)\n","        pos_enc_b = tf.math.cos(tf.tile(t, [1, channels // 2]) * inv_freq)\n","        pos_enc = tf.concat([pos_enc_a, pos_enc_b], axis=-1)\n","        return pos_enc\n","\n","class DifussionModel(tf.keras.Model):\n","    def __init__(self, x_shape, t_shape, c_in=3, c_out=3, time_dim=256, noise_steps=1000, beta_start=1e-4, beta_end=0.02, img_size=64):\n","        super().__init__()\n","        self.c_in = c_in\n","        self.c_out = c_out\n","        self.time_dim = time_dim\n","\n","        self.pos_enc_layer = PosEncLayer()\n","        \n","        self.inc = DoubleConv(c_in, 64, prefix=\"inc\")\n","        self.down1 = Down(64, 128, prefix=\"down1\")\n","        self.sa1 = SelfAttention(128, 32, prefix=\"self_att_1\")\n","        self.down2 = Down(128, 256, prefix=\"down2\")\n","        self.sa2 = SelfAttention(256, 16, prefix=\"self_att_2\")\n","        self.down3 = Down(256, 256, prefix=\"down3\")\n","        self.sa3 = SelfAttention(256, 8, prefix=\"self_att_3\")\n","\n","        self.bot1 = DoubleConv(256, 512, prefix=\"bot1\")\n","        self.bot2 = DoubleConv(512, 512, prefix=\"bot2\")\n","        self.bot3 = DoubleConv(512, 256, prefix=\"bot3\")\n","\n","        self.up1 = Up(512, 128, prefix=\"up1\")\n","        self.sa4 = SelfAttention(128, 16, prefix=\"self_att_4\")\n","        self.up2 = Up(256, 64, prefix=\"up2\")\n","        self.sa5 = SelfAttention(64, 32, prefix=\"self_att_5\")\n","        self.up3 = Up(128, 64, prefix=\"up3\")\n","        self.sa6 = SelfAttention(64, 64, prefix=\"self_att_6\")\n","        self.outc = tf.keras.layers.Conv2D(c_out, kernel_size=1, name=\"outc\")\n","\n","        # Diffusion args\n","        self.noise_layer = tf.keras.layers.GaussianNoise(stddev=1.0)\n","        self.noise_steps = noise_steps\n","        self.beta_start = beta_start\n","        self.beta_end = beta_end\n","        self.img_size = img_size\n","\n","        self.beta = tf.linspace(self.beta_start, self.beta_end, self.noise_steps)\n","        self.alpha = 1.0 - self.beta\n","        self.alpha_hat = tf.math.cumprod(self.alpha, axis=0)\n","        self.noise_rng = tf.random.Generator.from_non_deterministic_state()\n","    \n","    def call(self, x, t):\n","        t = self.pos_enc_layer(t, time_dim=self.time_dim)\n","        x1 = self.inc(x)\n","        x2 = self.down1(x1, t)\n","        x2 = self.sa1(x2)\n","        x3 = self.down2(x2, t)\n","        x3 = self.sa2(x3)\n","        x4 = self.down3(x3, t)\n","        x4 = self.sa3(x4)\n","\n","        x4 = self.bot1(x4)\n","        x4 = self.bot2(x4)\n","        x4 = self.bot3(x4)\n","\n","        x = self.up1(x4, x3, t)\n","        x = self.sa4(x)\n","        x = self.up2(x, x2, t)\n","        x = self.sa5(x)\n","        x = self.up3(x, x1, t)\n","        x = self.sa6(x)\n","        x = self.outc(x)\n","\n","        return x\n","\n","    def noise_images(self, x, t, epsilon):\n","        sqrt_alpha_hat = tf.math.sqrt(tf.gather(self.alpha_hat, t))[:, None, None, None]\n","        sqrt_one_minus_alpha_hat = tf.math.sqrt(1 - tf.gather(self.alpha_hat, t))[:, None, None, None]\n","        #epsilon = self.noise_layer(tf.ones_like(x) / 2.0, training=True)\n","        return sqrt_alpha_hat * x + sqrt_one_minus_alpha_hat * epsilon#, epsilon\n","\n","    def train_step(self, data):\n","        #x, t = data\n","        x, rnd = data\n","        t, noise = rnd\n","        t = tf.transpose(t)[0]\n","        x_t = self.noise_images(x, t, noise)\n","        with tf.GradientTape() as tape:\n","            predicted_noise = self(x_t, t, training=True)\n","            loss_value = self.compute_loss(y=noise, y_pred=predicted_noise)\n","        \n","        trainable_vars = self.trainable_variables\n","        gradients = tape.gradient(loss_value, trainable_vars)\n","        self.optimizer.apply_gradients(zip(gradients, trainable_vars))\n","        for metric in self.metrics:\n","            if metric.name == \"loss\":\n","                metric.update_state(loss_value)\n","            else:\n","                metric.update_state(noise, predicted_noise)\n","        return {m.name: m.result() for m in self.metrics}\n","    @tf.function\n","    def predict_step(self, data):\n","        #data = tf.Variable(data, trainable=False)\n","        for i in tf.range(self.noise_steps - 1, 0, -1, dtype='int32'):\n","            t = tf.cast(tf.ones(data.shape[0]), \"int32\") * i\n","            predicted_noise = self(data, t, training=False)\n","            alpha = tf.gather(self.alpha, t)[:, None, None, None]\n","            alpha_hat = tf.gather(self.alpha_hat, t)[:, None, None, None]\n","            beta = tf.gather(self.beta, t)[:, None, None, None]\n","            if i > 1:\n","                #noise = self.noise_layer(tf.ones_like(data), training=True)\n","                noise = self.noise_rng.normal(shape=data.shape, mean=0.0, stddev=1.0, dtype='float32')\n","            else:\n","                noise = tf.zeros_like(data)\n","            data = (1 / tf.math.sqrt(alpha)) * (data - ((1 - alpha) / (tf.math.sqrt(1 - alpha_hat))) * predicted_noise) + (tf.math.sqrt(beta) * noise)\n","        return data\n","\n","#net = DifussionModel(x_shape=(64, 64, 3, ), t_shape=(None, ))\n","#x_input = tf.random.uniform([4, 64, 64, 3])\n","#t_input = tf.constant([[500] * x_input.shape[0]])\n","#net(x_input, t_input)\n","#net.summary()"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T03:01:08.323176Z","iopub.status.busy":"2024-03-30T03:01:08.322848Z","iopub.status.idle":"2024-03-30T03:01:08.428462Z","shell.execute_reply":"2024-03-30T03:01:08.427407Z","shell.execute_reply.started":"2024-03-30T03:01:08.323150Z"},"trusted":true},"outputs":[],"source":["# Load test dataset\n","def random_generator(img_shape, t_shape, noise_steps):\n","    rng = tf.random.Generator.from_non_deterministic_state()\n","    \"\"\"\n","    IMPORTANT!!!\n","    For uniform(t values), shape must be [total_items, 1]\n","    For normal(noise), shape must be [total_items, W, H, C]\n","    \"\"\"\n","    uniform_gen = rng.uniform(shape=t_shape, minval=1, maxval=1000, dtype='int32')\n","    normal_gen = rng.split(1)[0].normal(shape=img_shape, mean=0.0, stddev=1.0, dtype='float32')\n","\n","    for t, noise in zip(uniform_gen, normal_gen):\n","        yield t, noise\n","\n","def get_random_ds(image_size, n_items, noise_steps):\n","    random_ds = tf.data.Dataset.from_generator(random_generator,\n","                                               args=([n_items, image_size, image_size, 3], [n_items, 1], noise_steps),\n","                                               output_signature=(\n","                                                    tf.TensorSpec(shape=(1), dtype='int32'),\n","                                                    tf.TensorSpec(shape=(image_size, image_size, 3), dtype='float32')))\n","    return random_ds.repeat(count=None)\n","\n","batch_size = 9\n","#img_dataset = tf.data.Dataset.load('/kaggle/input/generated-dataset/gen_dataset')\n","#img_dataset = tf.data.Dataset.load('/kaggle/input/testimages/saved_dataset')\n","img_dataset = tf.data.Dataset.load('/kaggle/input/mini-test-dataset/saved_dataset')\n","img_dataset = img_dataset.map(lambda x: tf.keras.layers.Normalization(mean=0.5, variance=0.25, axis=None)(x))\n","n_train = img_dataset.cardinality().numpy()\n","rnd_dataset = get_random_ds(64, n_train, 1000)\n","train_dataset = tf.data.Dataset.zip(img_dataset, rnd_dataset).shuffle(n_train).batch(batch_size).prefetch(batch_size)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-03-30T03:01:08.430263Z","iopub.status.busy":"2024-03-30T03:01:08.429863Z","iopub.status.idle":"2024-03-30T03:03:59.173326Z","shell.execute_reply":"2024-03-30T03:03:59.172319Z","shell.execute_reply.started":"2024-03-30T03:01:08.430231Z"},"trusted":true},"outputs":[],"source":["# Train UNet on it\n","import os\n","from shutil import make_archive\n","from zipfile import ZipFile\n","from PIL import Image, ImageDraw\n","\n","if not os.path.exists('/kaggle/working/all_images'):\n","    base_path = '/kaggle/working/all_images'\n","    os.makedirs(base_path)\n","    os.makedirs(base_path + '/gen_images')\n","    os.makedirs(base_path + '/result_images')\n","    os.makedirs(base_path + '/input')\n","    os.makedirs(base_path + '/noise')\n","    os.makedirs(base_path + '/prediction')\n","\n","class SampleCallback(tf.keras.callbacks.Callback):\n","    def on_epoch_end(self, epoch, logs=None):\n","        if epoch >= 0:#((epoch % 9) == 0 and epoch != 0) or epoch == 999:\n","            n = 10\n","            rng = tf.random.Generator.from_non_deterministic_state()\n","            x = rng.normal(shape=[n, self.model.img_size, self.model.img_size, 3], mean=0.0, stddev=1.0, dtype='float32')\n","            result = self.model.predict(x, batch_size=n)\n","            # Save results\n","            #result = tf.cast(((tf.clip_by_value(result, clip_value_min=-1.0, clip_value_max=1.0) + 1.0) / 2.0) * 255, dtype='uint8')\n","            #result = result.numpy()\n","            for i in range(n):\n","                #tf_image = Image.fromarray(result[i], 'RGB')\n","                #tf_image.save(f'all_images/result_images/tf_sample_{epoch}_{i}.jpg', quality=95)\n","                tf.keras.utils.save_img(f'all_images/result_images/{epoch}_result_{i}.jpg', result[i], data_format=\"channels_last\", scale=True)\n","\n","epochs = 500\n","model = DifussionModel(x_shape=(64, 64, 3, ), t_shape=(None, ))\n","#model = get_UNet_model((64, 64, 3, ), (), batch_size)\n","\n","mc = tf.keras.callbacks.ModelCheckpoint('test_unet.keras', monitor='loss', save_best_only=True, mode='min')\n","sc = SampleCallback()\n","\n","optimizer = tf.keras.optimizers.AdamW(learning_rate=3e-4)\n","mse_loss = tf.keras.losses.MeanSquaredError()\n","model.compile(optimizer=optimizer, loss=mse_loss, metrics=['mse'])\n","\n","model.fit(x=train_dataset, epochs=epochs, callbacks=[mc, sc])\n","\n","filename = \"saved_images_test_unet_nearest\"\n","directory = \"all_images\"\n","make_archive(filename, \"zip\", directory)\n","print(\"Finished!\")"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":4415294,"sourceId":7847327,"sourceType":"datasetVersion"},{"datasetId":4616804,"sourceId":7868630,"sourceType":"datasetVersion"}],"dockerImageVersionId":30664,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
